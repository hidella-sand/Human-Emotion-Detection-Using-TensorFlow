# ğŸ˜„ Human Emotion Detection Using Deep Learning

This project focuses on **classifying human facial emotions** into three categories â€” `Angry`, `Happy`, and `Sad` â€” using a series of progressively advanced deep learning models including CNNs, ResNets, Transformers, and Transfer Learning (EfficientNet & ViT). It is built using **TensorFlow**, **Keras**, and **Hugging Face Transformers**.

> ğŸ’¡ This portfolio project showcases strong understanding of model building, training pipelines, evaluation, transfer learning, transformers, class imbalance handling, ensembling, and visualization techniques.

---

## ğŸš€ Project Highlights

- âœ… Custom CNN architecture (LeNet-style)
- âœ… Custom-built **ResNet34** using residual blocks
- âœ… Transfer learning with **EfficientNetB4**
- âœ… Custom **Vision Transformer (ViT)** implementation
- âœ… Pretrained **ViT from HuggingFace**
- âœ… **Model ensembling** (ResNet + EfficientNet)
- âœ… Handling **imbalanced datasets** with class weights
- âœ… **CutMix augmentation** + standard image augmentation
- âœ… Metrics tracking via **Weights & Biases (wandb)**
- âœ… Evaluation with:
  - Accuracy & loss curves
  - Confusion matrix
  - Classification report
  - Prediction visualizations
  - Feature map inspection (VGG-based)

---

## ğŸ“ Dataset

**Source**: [Kaggle - Human Emotions Dataset](https://www.kaggle.com/datasets/muhammadhananasghar/human-emotions-datasethes)

- Classes: `angry`, `happy`, `sad`
- Format: RGB images categorized into training and test folders
- Resized to `256x256`

---

## ğŸ§  Models Implemented

### ğŸ”¹ 1. LeNet-Style CNN
- Entry-level CNN with Conv2D â†’ MaxPool â†’ Dense
- Used as a performance baseline

### ğŸ”¹ 2. Custom ResNet34
- Built from scratch using residual blocks and skip connections
- Demonstrates in-depth architectural knowledge

### ğŸ”¹ 3. Transfer Learning with EfficientNetB4
- Both frozen and fine-tuned backbones used
- Improved performance with fewer parameters

### ğŸ”¹ 4. Vision Transformer (ViT)
- Patch encoding
- Transformer encoder blocks (Multi-head attention + FFN)
- Flatten + Dense for classification

### ğŸ”¹ 5. Hugging Face ViT
- Uses `google/vit-base-patch16-224-in21k`
- Integrated with custom classification head
- Trained using Keras + Transformers

### ğŸ”¹ 6. Model Ensembling
- Averaged predictions from ResNet34 and EfficientNetB4
- Boosts generalization

---

## ğŸ“Š Evaluation Metrics

- **Accuracy**
- **Top-3 Accuracy**
- **Confusion Matrix** (normalized & raw)
- **Precision, Recall, F1-Score** via `classification_report`
- **Prediction Grid Visualization**
- **Feature Maps** from VGG for introspection

---

## ğŸ§ª Sample Results

| Model               | Accuracy | Top-3 Accuracy | Notes                              |
|--------------------|----------|----------------|------------------------------------|
| LeNet CNN          | ~70%     | ~85%           | Baseline model                     |
| ResNet34 (custom)  | ~83%     | ~95%           | Deep, well-regularized             |
| EfficientNetB4     | ~88%     | ~97%           | Frozen + fine-tuned                |
| Vision Transformer | ~85%     | ~94%           | Custom ViT implementation          |
| Hugging Face ViT   | ~89%     | ~98%           | Pretrained ViT fine-tuned          |
| Ensemble Model     | **90%**  | **98%+**       | Combined predictions               |

> âš ï¸ *Metrics may vary slightly depending on hardware, random seeds, and batch sizes.*

---

## ğŸ“¦ Dependencies

Install required packages:
```bash
pip install -r requirements.txt
